import db from "../../db.js";
import fs from "fs";
import fetch from "node-fetch";
import path from "path";
import { fileURLToPath } from "url";
import { spawn } from "child_process";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// ============================================================
// ‚öôÔ∏è SMART PATH CONFIGURATION (Dynamic for Windows/Linux)
// ============================================================

// 1. ‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á Root ‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå (senior-project)
// ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà: /backend/ml/data
// ‡∏ñ‡∏≠‡∏¢ 1 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á (..) -> /backend/ml
// ‡∏ñ‡∏≠‡∏¢ 2 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á (..) -> /backend
// ‡∏ñ‡∏≠‡∏¢ 3 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á (..) -> /senior-project (Root)
const projectRoot = path.resolve(__dirname, "../../../");

// 2. ‡πÄ‡∏ä‡πá‡∏Ñ OS ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Windows ‡∏´‡∏£‡∏∑‡∏≠ Linux
const isWindows = process.platform === "win32";

// 3. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Path Python ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
const PYTHON_PATH = isWindows
  ? path.join(projectRoot, "venv", "Scripts", "python.exe") // Windows
  : path.join(projectRoot, "venv", "bin", "python");        // Linux (VPS)

// 4. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Path ‡πÑ‡∏ü‡∏•‡πå Python Script
const TRAIN_SCRIPT_PATH = path.join(projectRoot, "backend", "ml", "model", "train_model.py");

// üî• DEBUG LOG: ‡πÄ‡∏ä‡πá‡∏Ñ Path ‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ô
console.log("-------------------------------------------------");
console.log(`üåç OS Detected:   ${process.platform}`);
console.log(`üìÇ Project Root:  ${projectRoot}`);
console.log(`üêç Python Path:   ${PYTHON_PATH}`);
console.log(`üìú Train Script:  ${TRAIN_SCRIPT_PATH}`);
console.log("-------------------------------------------------");

// ============================================================
// üìå PART 1: DATA INGESTION (API Fetching)
// Process: Data Mining & Collection
// ============================================================
async function fetchBooksFromAPI(queryVariables, label) {
  const gql = `
    query GetBooks($limit: Int!, $offset: Int!, $tagSlug: String) {
      books(
        where: {
          description: { _gt: "" }
          image_id: { _is_null: false }
          taggings: { tag: { slug: { _eq: $tagSlug } } } 
        }
        order_by: { users_read_count: desc } 
        limit: $limit
        offset: $offset
      ) {
        id, title, description, image { url }, contributions(limit: 1) { author { name } }, taggings(limit: 10) { tag { tag } }
      }
    }
  `;
  
  try {
    const response = await fetch("http://localhost:3000/api/search", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ query: gql, variables: queryVariables })
    });
    const json = await response.json();
    if (json.data && json.data.books) return json.data.books;
  } catch (err) { console.error(`‚ùå Fetch Error [${label}]:`, err.message); }
  return [];
}

async function fetchAllBooks() {
  const TARGET_TOTAL = 13000;
  console.log(`üîç [ETL Process] Starting Data Extraction (Target: ${TARGET_TOTAL} items)...`);
  let allBooksMap = new Map();
  
  // Diversity Coverage: ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î Bias
  const genres = [
    "fantasy", "sci-fi", "romance", "horror", "thriller", "mystery",
    "history", "biography", "business", "psychology", "self-help",
    "manga", "comics", "cooking", "travel", "art", "young-adult", "classics"
  ];

  for (const genre of genres) {
    if (allBooksMap.size >= TARGET_TOTAL) break;
    console.log(`\nüìÇ Fetching Category: ${genre.toUpperCase()}`);
    
    // Batch Processing
    for (let i = 0; i < 4; i++) {
        if (allBooksMap.size >= TARGET_TOTAL) break;
        const books = await fetchBooksFromAPI({ limit: 500, offset: i * 500, tagSlug: genre }, `${genre}-${i}`);
        
        if (!books || books.length === 0) break;
        
        books.forEach(b => allBooksMap.set(b.id, b));
        console.log(`   üìä Batch ${i+1}: Total Unique Records: ${allBooksMap.size}`);
        
        // Rate Limiting
        await new Promise(r => setTimeout(r, 100)); 
    }
  }

  // Data Cleaning & Formatting
  return Array.from(allBooksMap.values()).map(b => {
    const author = b.contributions?.[0]?.author?.name || "Unknown";
    const rawTags = b.taggings.map(t => t.tag.tag);
    // Feature Engineering
    const uniqueTags = [...new Set(rawTags)].filter(t => t.length < 20).slice(0, 8);
    const cleanDesc = (b.description || "").replace(/[\r\n]+/g, " ").replace(/\s+/g, ' ').trim();
    
    return {
      id: b.id,
      title: b.title || "Untitled",
      cover: b.image?.url || "",
      author: author,
      genres: uniqueTags.length ? uniqueTags : ["General"],
      description: cleanDesc
    };
  });
}

// ============================================================
// üìå PART 2: DATA TRANSFORMATION & LOADING (CSV Export)
// Process: Preparing Dataset for SBERT Model
// ============================================================
export async function exportBooks() {
  const allBooks = await fetchAllBooks();
  if (allBooks.length === 0) return;

  console.log("üíæ Writing Dataset to books.csv...");
  
  const csvLines = allBooks.map(b => {
    // Data Sanitization for CSV format
    const escape = (txt) => `"${String(txt).replace(/"/g, '""')}"`; 
    return [
        b.id, 
        escape(b.title), 
        escape(b.author), 
        escape(b.genres.join("|")), 
        escape(b.description), 
        escape(b.cover)
    ].join(",");
  });

  // Header must match Schema in train_model.py
  csvLines.unshift("book_id,title,authors,genres,description,image_url");
  fs.writeFileSync(path.join(__dirname, "books.csv"), csvLines.join("\n"));
  console.log("‚úÖ Dataset Ready.");
}

export async function exportUserPreferences() {
  console.log("üì• Exporting User Interaction Matrix...");
  try {
    const [rows] = await db.execute(`SELECT user_id, preferred_books FROM MPC`);
    const lines = [];
    rows.forEach(row => {
      let books = [];
      try { books = JSON.parse(row.preferred_books || "[]"); } catch {}
      books.forEach(bookId => lines.push(`${row.user_id},book,${bookId},1`));
    });
    fs.writeFileSync(path.join(__dirname, "user_preferences.csv"), lines.join("\n"));
    console.log("‚úÖ User Preferences Exported.");
  } catch (error) {
    console.error("‚ùå Error exporting prefs:", error);
  }
}

// ============================================================
// üìå PART 3: MODEL TRAINING TRIGGER
// Process: Executing Python Subprocess for Vectorization
// ============================================================
async function runTrainModel() {
  console.log("\nüß† Initializing Python Training Pipeline...");
  return new Promise((resolve, reject) => {
    
    if (!fs.existsSync(TRAIN_SCRIPT_PATH)) {
        console.error("‚ùå Python script not found at:", TRAIN_SCRIPT_PATH);
        console.error("   Please check directory structure (model vs models)");
        return reject();
    }

    const pythonProcess = spawn(PYTHON_PATH, [TRAIN_SCRIPT_PATH]);

    pythonProcess.stdout.on("data", (data) => console.log(`üêç [Python]: ${data.toString().trim()}`));
    pythonProcess.stderr.on("data", (data) => {
          const msg = data.toString().trim();
          if(msg && !msg.includes("oneDNN")) console.log(`‚ö†Ô∏è [Python Warning]: ${msg}`);
    });

    pythonProcess.on("close", (code) => {
      if (code === 0) {
        console.log("‚úÖ Model Training & Vectorization Completed Successfully!");
        resolve();
      } else {
        console.error("‚ùå Training Pipeline Failed with exit code:", code);
        reject(new Error("Training Failed"));
      }
    });
  });
}

// ============================================================
// üöÄ MAIN EXECUTION
// ============================================================
if (process.argv[1] === fileURLToPath(import.meta.url)) {
    (async () => {
        try {
            console.log("üöÄ Starting Recommendation System Pipeline...");
            await exportUserPreferences();
            await exportBooks();
            await runTrainModel();
            console.log("\n‚ú® Pipeline Finished. System is ready to serve recommendations.");
            process.exit(0);
        } catch (e) {
            console.error("‚ùå Pipeline Failed:", e);
            process.exit(1);
        }
    })();
}